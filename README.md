## ML-Project-1-Titanic-from-Disaster

#### Conclusion

In this project, I've built miltiple models to predict whether the subject survives or not. Since this is a Classification problem, I used classification models:
* Logisitc Regression (79.6%)
* KNN (67.4%)
* Decision Tree (74.1%)
* Random Forest (82.1%)
* SVM (67.4%)

As you can see, the best performing model was Random Foresting using the basic parameters. In general, models can be further improved by:
* Getting more data 
* Tuning the parameters 
* Using the other features given in the dataset that weren't used in this (Cabin, Ticket, Title from the Name)

This is a typical first real data science project that most people go through. With that being said, there are many examples of this kernal throughout kaggle. I have attempted my best to use what I know and limited myself on using other kernals available.

#### Data Source

For this project, I'll be applying the Logistic Regression algorithm on the famous [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) dataset!
  
#### Data Description

There are 12 columns and 891 entries/rows. You can find more about what each column represents by going to the dataset I linked

#### Project Goal

 The goal for this project:
* Apply multiple classification machine learning algorithm 
    * Logisitc Regression
    * KNN
    * Decision Tree
    * Random Foresting
    * SVM
* Predict survival or deceased


##### Final thoughts

This is my first project where I've tried to apply a lot of the things I've learned on Data Science. From Importing data, analyzing, visualizing, building different models, tuning the models, and evaluate my models. There are many things I could learn such as but not limited to:
* Learning Other models 
    * Naive Bayes
    * Extreme Gradiant boosting 
* Apply ensemble approach (use a combination of different models)
